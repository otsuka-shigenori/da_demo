{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "da_demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6RN4Q4SvKZj"
      },
      "source": [
        "このノートブックではデータ同化の基礎的なアルゴリズムを示します。\n",
        "\n",
        "1. 実験に使うカオス力学系のモデルを用意\n",
        "2. 拡張カルマンフィルタの実装\n",
        "3. アンサンブルカルマンフィルタを摂動観測法で実装\n",
        "4. アンサンブルカルマンフィルタをLETKFで実装\n",
        "\n",
        "まずはライブラリの読み込みを行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXxK4hDTtw-S"
      },
      "source": [
        "import math                              # 数学ライブラリ\n",
        "import numpy as np                       # 数値計算用の配列\n",
        "import numpy.linalg as LA                # 行列計算ライブラリ\n",
        "import matplotlib.pyplot as plt          # 可視化ライブラリ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPBov05igeHf"
      },
      "source": [
        "Lorenz and Emanuel (1998, <i>Journal of the Atmospheric Science</i>)のカオス力学系を題材にします。\n",
        "\n",
        "地球を東西に一周する大気の変動を模したモデルです。\n",
        "モデルの方程式は以下で与えられます。\n",
        "\n",
        "$\\displaystyle \\frac{dx_j}{dt} = (x_{j+1} - x_{j-2})x_{j-1} - x_j + F$\n",
        "\n",
        "$j = 1, ..., n$, 周期境界条件\n",
        "\n",
        "第一項は波動の伝播、第二項はエネルギー減衰、第三項の$F$は外部強制力を模していて、$F$が4以上になると徐々に非周期解に遷移し、$F$が大きいほどカオス的に振る舞います。\n",
        "\n",
        "通常、$n = 40$ を使います。以下の実験では $F = 8$ とします。\n",
        "\n",
        "以下、時刻 $i$ の $x_j$, $j = 1, ..., n$ をまとめて $\\mathbf{x}_i$ と表します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KkTvzfouGpX"
      },
      "source": [
        "class Lorenz96:\n",
        "  \"\"\"\n",
        "  This class provides the Lorenz96 model equations and the 4th-order Runge-Kutta solver.\n",
        "  \"\"\"\n",
        "  def __init__(self, n = 40, f = 8, dt = 0.005, init_x = None):\n",
        "    self.f = f\n",
        "    self.dt = dt\n",
        "    if init_x is not None:\n",
        "      self.x = init_x\n",
        "    else:\n",
        "      self.x = np.zeros(n, dtype=np.float64)\n",
        "    # temporary memory\n",
        "    self.tmpx = np.zeros(n + 3, dtype=np.float64)\n",
        "    return\n",
        "  \n",
        "  def dx_dt(self, y):\n",
        "    n = y.shape[0]\n",
        "    m = n + 3\n",
        "    self.tmpx[2:(m - 1)] = y[:]\n",
        "    # cyclic boundary condition\n",
        "    self.tmpx[0:2] = y[(n - 2):n]\n",
        "    self.tmpx[m - 1] = y[0]\n",
        "    tmpdx = (self.tmpx[3:m] - self.tmpx[0:(m - 3)]) * self.tmpx[1:(m - 2)] - self.tmpx[2:(m - 1)] + self.f\n",
        "    return tmpdx\n",
        "\n",
        "  def runge_kutta(self):\n",
        "    dx1 = self.dx_dt(self.x)\n",
        "    x1  = self.x + dx1 * (self.dt * 0.5)\n",
        "    dx2 = self.dx_dt(x1)\n",
        "    x2  = self.x + dx2 * (self.dt * 0.5)\n",
        "    dx3 = self.dx_dt(x2)\n",
        "    x3  = self.x + dx3 * self.dt\n",
        "    dx4 = self.dx_dt(x3)\n",
        "    self.x += (dx1 + 2.0 * (dx2 + dx3) + dx4) * (self.dt / 6.0)\n",
        "    return self.x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DpukUa2JSvU"
      },
      "source": [
        "以下で使うモデルのサイズをここで設定しておきます。もし実行が遅いと感じる場合は、$n = 20$ などに減らしてみて下さい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lZp6qVnJcFD"
      },
      "source": [
        "# model size\n",
        "n = 40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNaaIy6pgRNB"
      },
      "source": [
        "適当な乱数を初期値に与えてモデルを実行し、真値とします。\n",
        "\n",
        "真値に正規乱数を加えて疑似観測データを生成します。\n",
        "\n",
        "疑似観測データを別のモデル（同じでも良い）でデータ同化する実験を行います。\n",
        "\n",
        "Observing System Simulation Experiment (OSSE)と呼びます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPgI6AQGcqoC"
      },
      "source": [
        "真値  $\\mathbf{x}^t_i$ を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71pU0Iy2SOB1"
      },
      "source": [
        "exp_length = 40 * 180\n",
        "\n",
        "x0 = np.array(np.random.randn(n), dtype=np.float64)\n",
        "l96 = Lorenz96(n, init_x = x0)\n",
        "nature = []\n",
        "for i in range(exp_length):\n",
        "  nature.append(l96.runge_kutta().copy())\n",
        "nature = np.array(nature, dtype=np.float64)\n",
        "\n",
        "print(nature.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqqmDNUxgJM5"
      },
      "source": [
        "作成した真値を可視化してみます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USkgRkh8b3dr"
      },
      "source": [
        "plt.contourf(nature[0:(40 * 30), :])\n",
        "plt.xlabel('location')\n",
        "plt.ylabel('time step')\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sJbqXIHNI1R"
      },
      "source": [
        "カオス力学系であることを見てみましょう。真値に途中で微小擾乱を与えて、続きを計算してみます。両者の差の時間変化を見てみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOfV4bbpNQhQ"
      },
      "source": [
        "iter_pert = 40 * 30\n",
        "\n",
        "xpert = nature[iter_pert].copy()\n",
        "xpert[0] += 1.0e-5\n",
        "l96 = Lorenz96(n, init_x = xpert)\n",
        "perturbed = [xpert.copy()]\n",
        "t = [0]\n",
        "for i in range(exp_length - iter_pert - 1):\n",
        "  perturbed.append(l96.runge_kutta().copy())\n",
        "  t.append(i)\n",
        "perturbed = np.array(perturbed, dtype=np.float64)\n",
        "\n",
        "diff = perturbed - nature[iter_pert:]\n",
        "rmse = np.sqrt(np.sum(diff * diff, 1) / n)\n",
        "\n",
        "plt.plot(t, rmse)\n",
        "plt.yscale('log')\n",
        "plt.xlabel('time step')\n",
        "plt.ylabel('root mean square error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shZOkUG4P-2t"
      },
      "source": [
        "最初はroot mean square errorが指数関数的に増大していきます。あるところまで増大すると、誤差の非線形性が卓越してきて、誤差の振幅が飽和します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5yW_k26v9hf"
      },
      "source": [
        "データ同化実験の準備をします。\n",
        "\n",
        "真値に平均0、分散1の正規乱数を加えて疑似観測 $\\mathbf{y}^o_i$ を作成します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Eh1OwOtm0WM"
      },
      "source": [
        "obs_err_std = 1.0\n",
        "obs = nature + np.random.randn(nature.shape[0], nature.shape[1]) * obs_err_std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hQJWBNyvwm_"
      },
      "source": [
        "plt.contourf(obs[0:(40 * 30), :])\n",
        "plt.xlabel('location')\n",
        "plt.ylabel('time step')\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JG1HTLa2hX-"
      },
      "source": [
        "最初の方はモデルが十分に落ち着いていないので捨てます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlPaXUCZ2p_t"
      },
      "source": [
        "n_spinup = 40 * 30\n",
        "nature = nature[n_spinup:]\n",
        "obs = obs[n_spinup:]\n",
        "exp_length -= n_spinup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9WlApUmrBxG"
      },
      "source": [
        "拡張カルマンフィルタを構築します。以下の式で与えられます。\n",
        "\n",
        "1. 時刻 $i$ から $i + 1$ への予報：\n",
        "\n",
        "$\\mathbf{x}^f_{i + 1} = M(\\mathbf{x}^a_i) $：状態変数の予報\n",
        "\n",
        "$\\displaystyle \\mathsf{M}_i = \\left.\\frac{\\partial M}{\\partial \\mathbf{x}}\\right|_{\\mathbf{x}^a_i \\rightarrow \\mathbf{x}^f_{i + 1}}$ ：接線型モデル\n",
        "\n",
        "$\\mathsf{P}^f_{i + 1} = \\mathsf{M}_i\\mathsf{P}^a_i\\mathsf{M}^T_i$ ：予報誤差共分散\n",
        "\n",
        "2. 時刻 $i$ での解析：\n",
        "\n",
        "$\\mathbf{y}^o_i$ ：観測データ\n",
        "\n",
        "$\\mathbf{y}^f_i = h_i(\\mathbf{x}^f_i) $：モデル状態変数 $\\mathbf{x}^f_i$ から観測相当量 $\\mathbf{y}^f_i$ への写像（観測演算子）\n",
        "\n",
        "$\\displaystyle \\mathsf{H}_i = \\left.\\frac{\\partial h_i}{\\partial \\mathbf{x}}\\right|_{\\mathbf{x}^f_{i}}$ ：観測演算子の接線形近似（以下では観測演算子が線形と仮定して $h_i(\\cdot)$ をそのまま使用）\n",
        "\n",
        "$\\mathsf{R}_i$ ：観測誤差共分散（独立性が仮定できれば対角行列）\n",
        "\n",
        "$\\mathsf{K}_i = \\mathsf{P}^f_i \\mathsf{H}^T_i (\\mathsf{H}_i \\mathsf{P}^f_i \\mathsf{H}^T_i + \\mathsf{R}_i)^{-1}$ ：カルマンゲイン\n",
        "\n",
        "$\\mathbf{x}^a_i = \\mathbf{x}^f_i + \\mathsf{K}_i (\\mathbf{y}^o_i - \\mathbf{y}^f_i)$ ：状態変数の解析\n",
        "\n",
        "$\\mathsf{P}^a_i = (\\mathsf{I} - \\mathsf{K}_i \\mathsf{H}_i)\\mathsf{P}^f_i$ ：解析誤差共分散"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQBBJdOJfJxi"
      },
      "source": [
        "class KalmanFilter:\n",
        "  def __init__(self, model, n = 40, f = 8, dt = 0.005):\n",
        "    \"\"\"\n",
        "    model: model constructor\n",
        "    n: model size\n",
        "    f: external forcing\n",
        "    dt: time interval of model time integration\n",
        "    n, f, dt will be passed to the model constructor\n",
        "    \"\"\"\n",
        "    self.n = n\n",
        "    self.f = f\n",
        "    self.dt = dt\n",
        "    # model for the state\n",
        "    self.model = model(n, f, dt)\n",
        "    # models to approximate tangent linear model\n",
        "    self.ensemble = []\n",
        "    for i in range(n):\n",
        "      self.ensemble.append(model(n, f, dt))\n",
        "    # background error covariance matrix\n",
        "    self.p_f = np.identity(n, dtype=np.float64)\n",
        "    return\n",
        "  \n",
        "  def forward(self):\n",
        "    \"\"\"\n",
        "    This function updates the model state and the background error covariance matrix.\n",
        "    \"\"\"\n",
        "    tmpx = self.model.x.copy()\n",
        "    # update state\n",
        "    self.model.runge_kutta()\n",
        "    # approximate tangent linear model\n",
        "    eps = 1.0e-8\n",
        "    m = np.zeros_like(self.p_f)\n",
        "    for i in range(self.n):\n",
        "      self.ensemble[i].x[:] = tmpx[:]\n",
        "      self.ensemble[i].x[i] += eps\n",
        "      self.ensemble[i].runge_kutta()\n",
        "      m[:, i] = self.ensemble[i].x[:]\n",
        "    m -= self.model.x[:, np.newaxis]\n",
        "    m /= eps\n",
        "    # update background error covariance matrix\n",
        "    self.p_f = m @ self.p_f @ (m.T)\n",
        "    return self.model.x, self.p_f\n",
        "\n",
        "  def analysis(self, h, y, r):\n",
        "    \"\"\"\n",
        "    This function performs the Kalman filtering.\n",
        "    h: observation operator matrix\n",
        "    y: a vector of observations\n",
        "    r: observation error covariance matrix\n",
        "    \"\"\"\n",
        "    if len(self.model.x.shape) == 1:\n",
        "      xx = self.model.x[:, np.newaxis]\n",
        "    else:\n",
        "      xx = self.model.x\n",
        "    if len(y.shape) == 1:\n",
        "      yy = y[:, np.newaxis]\n",
        "    else:\n",
        "      yy = y\n",
        "    kalman_gain = self.p_f @ (h.T) @ LA.inv(h @ self.p_f @ (h.T) + r)\n",
        "    xx += kalman_gain @ (yy - h @ xx)\n",
        "    self.p_f = (np.identity(self.n, dtype=np.float64) - kalman_gain @ h) @ self.p_f\n",
        "    return self.model.x, self.p_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcFVauLv3CAj"
      },
      "source": [
        "データ同化サイクルを回してみます。\n",
        "\n",
        "$n = 40$ として、40点すべてを観測するとします。\n",
        "データ同化の頻度は、モデルの時間積分10ステップに1回とします。\n",
        "\n",
        "状態変数の初期値は 0、予報誤差共分散行列の初期値は単位行列にしています。\n",
        "\n",
        "（Lorenz96モデルは $F=8$ の時に、0.4無次元時間で誤差が約2倍になります。地球大気では大規模波動（温帯低気圧など）の誤差が2日で倍になる傾向があるため、ここでは0.2無次元時間を1日と考え、通常の気象観測と同様に1日4回観測することにします。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taipqFDfnS7k"
      },
      "source": [
        "kf = KalmanFilter(Lorenz96, n)\n",
        "# set observation error covariance matrix (diagonal)\n",
        "r = np.identity(n, dtype=np.float64) * obs_err_std\n",
        "# set observation operator matrix (use identity)\n",
        "h = np.identity(n, dtype=np.float64)\n",
        "x = []\n",
        "analysis_intv = 10\n",
        "\n",
        "# MAIN LOOP\n",
        "for i in range(exp_length // analysis_intv):\n",
        "  for j in range(analysis_intv):\n",
        "    # time (i * analysis_intv + j) to (i * analysis_intv + j + 1)\n",
        "    xf, pf = kf.forward()\n",
        "  if (i + 1) * analysis_intv < exp_length:\n",
        "    if i % 100 == 0:\n",
        "      print(\"analysis \", i)\n",
        "    else:\n",
        "      print(\".\", end=\"\")\n",
        "    xa, pa = kf.analysis(h, obs[(i + 1) * analysis_intv, :], r)\n",
        "    x.append(((i + 1) * analysis_intv, xa.copy()))\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u63p4jSpyHvj"
      },
      "source": [
        "うまく動いたか、確認します。真値とのずれをroot mean square errorの時系列で見てみます。\n",
        "\n",
        "観測誤差を1.0としているので、それより大きいか小さいか確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-6Dm_y_yQhb"
      },
      "source": [
        "rmse = []\n",
        "for xx in x:\n",
        "  if xx[0] < nature.shape[0]:\n",
        "    rmse.append((xx[0], math.sqrt(((nature[xx[0]] - xx[1]) ** 2).sum() / n)))\n",
        "rmse = np.array(rmse) \n",
        "\n",
        "plt.plot(rmse[:, 0], rmse[:, 1])\n",
        "plt.xlabel('time step')\n",
        "plt.ylabel('root mean square error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-QoU4J-2jLe"
      },
      "source": [
        "最初はうまく動いているように見えますが、途中から悪くなっているのが分かるかと思います。\n",
        "\n",
        "これは、非線形モデルに対して接線形近似を行って線形最適化問題を解いているため、予報誤差共分散が過小評価される傾向にあるためです。\n",
        "\n",
        "対策として、予報誤差共分散を人工的に膨張させます（誤差共分散膨張）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_rzNVSt3DfY"
      },
      "source": [
        "kf = KalmanFilter(Lorenz96, n)\n",
        "# set observation error covariance matrix (diagonal)\n",
        "r = np.identity(n, dtype=np.float64) * obs_err_std\n",
        "# set observation operator matrix (use identity)\n",
        "h = np.identity(n, dtype=np.float64)\n",
        "x_new = []\n",
        "pa_hist = []\n",
        "analysis_intv = 10\n",
        "\n",
        "# MAIN LOOP\n",
        "for i in range(exp_length // analysis_intv):\n",
        "  for j in range(analysis_intv):\n",
        "    # time (i * analysis_intv + j) to (i * analysis_intv + j + 1)\n",
        "    xf, pf = kf.forward()\n",
        "  if (i + 1) * analysis_intv < exp_length:\n",
        "    if i % 100 == 0:\n",
        "      print(\"analysis \", i)\n",
        "    else:\n",
        "      print(\".\", end=\"\")\n",
        "    # multiplicative covariance inflation\n",
        "    kf.p_f *= 1.1\n",
        "    #\n",
        "    xa, pa = kf.analysis(h, obs[(i + 1) * analysis_intv, :], r)\n",
        "    x_new.append(((i + 1) * analysis_intv, xa.copy()))\n",
        "    pa_hist.append(pa.copy())\n",
        "pa_mean = np.mean(np.array(pa_hist), 0)\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMt7SdcQ3Xj6"
      },
      "source": [
        "結果を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY3kMVxH3Wqi"
      },
      "source": [
        "rmse = []\n",
        "for xx in x_new:\n",
        "  if xx[0] < nature.shape[0]:\n",
        "    rmse.append((xx[0], math.sqrt(((nature[xx[0]] - xx[1]) ** 2).sum() / n)))\n",
        "rmse = np.array(rmse) \n",
        "\n",
        "plt.plot(rmse[:, 0], rmse[:, 1])\n",
        "plt.xlabel('time step')\n",
        "plt.ylabel('root mean square error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0robvxJ90Ui"
      },
      "source": [
        "誤差が低く抑えられていることが分かります。\n",
        "\n",
        "Lorenz96モデルでカルマンフィルタを動かすと、観測誤差の標準偏差が1.0の場合は、解析root mean square errorは約0.2になります。\n",
        "\n",
        "つまり、観測誤差よりも解析誤差を小さくすることが出来ます。\n",
        "\n",
        "次に、カルマンフィルタの肝である、誤差共分散行列を見てみます。まずは瞬間値です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxH4oUbnBrLX"
      },
      "source": [
        "max = np.max(np.abs(kf.p_f))\n",
        "plt.pcolormesh(kf.p_f, cmap=\"nipy_spectral\", vmin=-max, vmax=max)\n",
        "plt.gca().set_aspect('equal')\n",
        "plt.xlabel('location')\n",
        "plt.ylabel('location')\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El5_bYn2L67I"
      },
      "source": [
        "時間平均したものも見てみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPZcUIr9L4Nd"
      },
      "source": [
        "max = np.max(np.abs(pa_mean))\n",
        "plt.pcolormesh(pa_mean, cmap=\"nipy_spectral\", vmin=-max, vmax=max)\n",
        "plt.gca().set_aspect('equal')\n",
        "plt.xlabel('location')\n",
        "plt.ylabel('location')\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKDxljO8CJ9G"
      },
      "source": [
        "対称行列で、非対角成分はほとんどの場所で小さいですが、対角成分とその周辺に構造が見えます。\n",
        "\n",
        "元の予報方程式では、自分の点の前後2点先までを含む式になっています。そのため、対角成分から二つ隣まで、大きな値が入る傾向があります。\n",
        "\n",
        "この構造が、時々刻々と変化します。それに応じて観測の情報を最適に取り込むことで、精度の高い解析を実現します。\n",
        "\n",
        "この行列の大きさは、元のモデルの次元の二乗になります。低次元のシステムでは陽に行列を持つことが出来ますが、大次元のシステムでは行列が計算機のメモリーに乗らなくなります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVRaKD9TB58j"
      },
      "source": [
        "大次元システムにカルマンフィルタを適用する場合には、予報誤差共分散行列を陽に持たず、摂動を加えたシミュレーションを多数実行して変数間の相関を見積もる、アンサンブルカルマンフィルタが用いられます。\n",
        "\n",
        "実装方法は複数ありますが、大別すると以下の二つです：\n",
        "\n",
        "\n",
        "1.   摂動観測法　Perturbed Observation (PO) method\n",
        "2.   平方根フィルタ　Square root filter (SRF)\n",
        "\n",
        "平方根フィルタはさらに多数の実装方法に細分化されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh-pCmk0ICIl"
      },
      "source": [
        "PO法の式は以下で与えられます。\n",
        "\n",
        "1. 時刻 $i$ から $i + 1$ への予報：\n",
        "\n",
        "$\\mathbf{x}^{f(k)}_{i + 1} = M \\left(x^{a(k)}_i \\right)$ ：状態変数のアンサンブル予報 ($k = 1, ..., m$)\n",
        "\n",
        "2. 時刻 $i$ でのアンサンブル平均場の解析：\n",
        "\n",
        "$\\displaystyle \\mathbf{x}^f_{i + 1} = \\frac{1}{m} \\sum_{k = 1}^K \\mathbf{x}^{f(k)}_{i + 1}$ ：アンサンブル平均場\n",
        "\n",
        "$\\mathbf{dx}^{(k)} = \\mathbf{x}^{f(k)}_{i + 1} - \\mathbf{x}^f_{i + 1}$ ：アンサンブル摂動\n",
        "\n",
        "$\\displaystyle \\mathsf{Z}_{i + 1} = \\frac{1}{\\sqrt{m - 1}} \\left(\\mathbf{dx}^{(1)}, \\mathbf{dx}^{(2)}, ..., \\mathbf{dx}^{(K)} \\right)$ ：アンサンブル摂動の列ベクトルを束ねた行列\n",
        "\n",
        "$\\mathsf{P}^f_{i + 1} = \\mathsf{Z}_{i + 1} \\mathsf{Z}^T_{i + 1}$ ：予報誤差共分散の近似（実際には解かない）\n",
        "\n",
        "$\\mathsf{Y}_{i + 1} = \\mathsf{H}_{i + 1} \\mathsf{Z}_{i + 1}$ ：アンサンブル摂動の観測空間への写像\n",
        "\n",
        "$\\mathsf{K}_i = \\mathsf{Z}_i \\mathsf{Y}^T_i (\\mathsf{Y}_i \\mathsf{Y}^T_i + \\mathsf{R}_i)^{-1}$ ：カルマンゲイン\n",
        "\n",
        "$\\mathbf{x}^a_i = \\mathbf{x}^f_i + \\mathsf{K}_i (\\mathbf{y}^o_i - \\mathsf{H}_i \\mathbf{x}^f_i)$ ：状態変数の解析\n",
        "\n",
        "3. 時刻 $i$ での各アンサンブルメンバーの解析：\n",
        "\n",
        "$\\sigma^o$ ：観測誤差共分散 $\\mathsf{R}_i$ の対角成分の平方根\n",
        "\n",
        "$\\mathbf{y}^{o(k)} = \\mathbf{y}^o + N(0, \\sigma^o)$ ：観測に観測誤差相当の正規乱数を加える（各アンサンブルメンバー、各変数独立に）\n",
        "\n",
        "$\\mathbf{x}^{a(k)}_i = \\mathbf{x}^{f(k)}_i + \\mathsf{K}_i (\\mathbf{y}^{o(k)}_i - \\mathsf{H}_i \\mathbf{x}^{f(k)}_i)$ ：状態変数の解析\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk4UzeAh26PF"
      },
      "source": [
        "class EnKF_PO:\n",
        "  def __init__(self, model, n = 40, f = 8, dt = 0.005, k = 20, localization = None):\n",
        "    \"\"\"\n",
        "    model: model constructor\n",
        "    n: model size\n",
        "    f: external forcing\n",
        "    dt: time interval of model time integration\n",
        "    n, f, dt will be passed to the model constructor\n",
        "    k: ensemble size\n",
        "    localization: K-localization length scale (if it is not None)\n",
        "    \"\"\"\n",
        "    self.n = n\n",
        "    self.f = f\n",
        "    self.dt = dt\n",
        "    self.k = k\n",
        "    self.localization = localization\n",
        "    # models\n",
        "    self.ensemble = []\n",
        "    for i in range(k):\n",
        "      self.ensemble.append(model(n, f, dt))\n",
        "    return\n",
        "  \n",
        "  def forward(self):\n",
        "    \"\"\"\n",
        "    This function updates the model state.\n",
        "    \"\"\"\n",
        "    for i in range(self.k):\n",
        "      self.ensemble[i].runge_kutta()\n",
        "    return\n",
        "\n",
        "  def mean(self):\n",
        "    x_mean = self.ensemble[0].x.copy()\n",
        "    for i in range(1, self.k):\n",
        "      x_mean += self.ensemble[i].x\n",
        "    x_mean /= self.k\n",
        "    return x_mean\n",
        "\n",
        "  def k_localization(self, h, scale):\n",
        "    loc = np.zeros(h.shape[0], dtype=np.float64)\n",
        "    for i in range(h.shape[0]):\n",
        "      tmploc = 0\n",
        "      tmpweight = 0\n",
        "      for j in range(h.shape[1]):\n",
        "        abs = np.abs(h[i, j])\n",
        "        tmploc += j * abs\n",
        "        tmpweight += abs\n",
        "      loc[i] = tmploc / tmpweight\n",
        "    k_loc = np.zeros_like(h.T)\n",
        "    for i in range(h.shape[0]): # num of obs\n",
        "      for j in range(h.shape[1]): # model size\n",
        "        dist = np.min(np.mod(np.array((loc[i] - j, j - loc[i])), n))\n",
        "        k_loc[j, i] = math.exp(-((dist / (math.sqrt(2) * scale)) ** 2)) # Gaussian tapering\n",
        "    return k_loc\n",
        "\n",
        "  def analysis(self, h, y, r):\n",
        "    \"\"\"\n",
        "    This function performs the Ensemble Kalman filtering.\n",
        "    h: observation operator matrix\n",
        "    y: a vector of observations\n",
        "    r: observation error covariance matrix\n",
        "    \"\"\"\n",
        "    xx = self.mean()[:, np.newaxis]\n",
        "\n",
        "    z = np.zeros((self.n, self.k), dtype=np.float64)\n",
        "    for i in range(self.k):\n",
        "      z[:, i] = self.ensemble[i].x\n",
        "    z -= xx\n",
        "    z /= math.sqrt(self.k - 1)\n",
        "    hz = h @ z\n",
        "\n",
        "    if len(y.shape) == 1:\n",
        "      yy = y[:, np.newaxis]\n",
        "    else:\n",
        "      yy = y\n",
        "\n",
        "    kalman_gain = z @ (hz.T) @ LA.inv(hz @ (hz.T) + r)\n",
        "    if self.localization is not None:\n",
        "      kalman_gain *= self.k_localization(h, self.localization)\n",
        "\n",
        "    # mean update\n",
        "    xx += kalman_gain @ (yy - h @ xx)\n",
        "\n",
        "    # ensemble update\n",
        "    obs_err = np.zeros((y.shape[0], 1))\n",
        "    for i in range(y.shape[0]):\n",
        "      obs_err[i, 0] = r[i, i]\n",
        "    obs_err = np.sqrt(obs_err)\n",
        "    for i in range(self.k):\n",
        "      x_ens = self.ensemble[i].x[:, np.newaxis]\n",
        "      yy_pert = yy + np.random.randn(y.shape[0], 1) * obs_err\n",
        "      x_ens += kalman_gain @ (yy_pert - h @ x_ens)\n",
        "\n",
        "    return xx[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuuAue_oCsqp"
      },
      "source": [
        "アンサンブル数10で実験してみます。\n",
        "\n",
        "アンサンブル予報の初期値は標準偏差10の正規乱数にしています。\n",
        "\n",
        "（モデル状態変数の変動幅がそのくらいあるため。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDqltanNA6pj"
      },
      "source": [
        "kk = 10 # ensemble size\n",
        "enkf_po = EnKF_PO(Lorenz96, n, k = kk)\n",
        "# initial ensemble perturbation\n",
        "for i in range(kk):\n",
        "  enkf_po.ensemble[i].x += np.random.randn(n) * 10.0 # approximate error of the initial state\n",
        "# set observation error covariance matrix (diagonal)\n",
        "r = np.identity(n, dtype=np.float64) * obs_err_std\n",
        "# set observation operator matrix (use identity)\n",
        "h = np.identity(n, dtype=np.float64)\n",
        "x_po10 = []\n",
        "analysis_intv = 10\n",
        "\n",
        "# MAIN LOOP\n",
        "for i in range(exp_length // analysis_intv):\n",
        "  for j in range(analysis_intv):\n",
        "    # time (i * analysis_intv + j) to (i * analysis_intv + j + 1)\n",
        "    xf = enkf_po.forward()\n",
        "  if (i + 1) * analysis_intv < exp_length:\n",
        "    if i % 100 == 0:\n",
        "      print(\"analysis \", i)\n",
        "    else:\n",
        "      print(\".\", end=\"\")\n",
        "    # multiplicative covariance inflation\n",
        "    x_mean = enkf_po.mean()\n",
        "    for ii in range(kk):\n",
        "      enkf_po.ensemble[ii].x = x_mean + (enkf_po.ensemble[ii].x - x_mean) * math.sqrt(1.1)\n",
        "    #\n",
        "    xa = enkf_po.analysis(h, obs[(i + 1) * analysis_intv, :], r)\n",
        "    x_po10.append(((i + 1) * analysis_intv, xa))\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBjw5wbEKqMg"
      },
      "source": [
        "結果はどうでしょうか。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRrriQq1EjRA"
      },
      "source": [
        "rmse = []\n",
        "for xx in x_po10:\n",
        "  if xx[0] < nature.shape[0]:\n",
        "    rmse.append((xx[0], math.sqrt(((nature[xx[0]] - xx[1]) ** 2).sum() / n)))\n",
        "rmse = np.array(rmse) \n",
        "\n",
        "plt.plot(rmse[:, 0], rmse[:, 1])\n",
        "plt.xlabel('time step')\n",
        "plt.ylabel('root mean square error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vst0usEuEneq"
      },
      "source": [
        "アンサンブル数が少ないと、一般にうまく動かないです。\n",
        "\n",
        "アンサンブルカルマンフィルタは、アンサンブルメンバー間の相関を使って予報誤差共分散を近似します（モンテカルロ近似）。アンサンブル数が少ないと、サンプリング誤差が大きくなります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q6SWkwRFl-r"
      },
      "source": [
        "xx = enkf_po.mean()[:, np.newaxis]\n",
        "\n",
        "z = np.zeros((enkf_po.n, enkf_po.k), dtype=np.float64)\n",
        "for i in range(enkf_po.k):\n",
        "  z[:, i] = enkf_po.ensemble[i].x\n",
        "z -= xx\n",
        "z /= math.sqrt(enkf_po.k - 1)\n",
        "p_f = z @ (z.T)\n",
        "\n",
        "max = np.max(np.abs(p_f))\n",
        "plt.pcolormesh(p_f, cmap=\"nipy_spectral\", vmin=-max, vmax=max)\n",
        "plt.gca().set_aspect('equal')\n",
        "plt.xlabel('location')\n",
        "plt.ylabel('location')\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b23RU2RMFjEU"
      },
      "source": [
        "サンプリング誤差を抑えるため、予報誤差共分散の局所化を行います。\n",
        "\n",
        "物理的に相関が無いと考えられる変数間（例えば遠く離れた点同士）の相関を人為的に低下させます。\n",
        "\n",
        "ここでは距離に応じて正規分布で減衰させます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W3rm81eVbky"
      },
      "source": [
        "scale = 5.0 # localization length scale\n",
        "for i in range(enkf_po.n - 1):\n",
        "  for j in range(i + 1, enkf_po.n):\n",
        "    dist = np.min(np.mod(np.array((j - i, i - j)), n))\n",
        "    p_f[i, j] *= math.exp(-((dist / (math.sqrt(2) * scale)) ** 2)) # Gaussian tapering\n",
        "    p_f[j, i] = p_f[i, j]\n",
        "\n",
        "max = np.max(np.abs(p_f))\n",
        "plt.pcolormesh(p_f, cmap=\"nipy_spectral\", vmin=-max, vmax=max)\n",
        "plt.gca().set_aspect('equal')\n",
        "plt.xlabel('location')\n",
        "plt.ylabel('location')\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swq2DOzEdsGV"
      },
      "source": [
        "予報誤差共分散行列を陽に解かないアンサンブルカルマンフィルタの実装においては、近似的に実装されます。カルマンゲインを調節する方法と、観測誤差を調整する方法があります。ここではカルマンゲインを調節します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBz3oygRZwtt"
      },
      "source": [
        "kk = 10 # ensemble size\n",
        "scale = 3 # localization scale\n",
        "enkf_po = EnKF_PO(Lorenz96, n, k = kk, localization = scale)\n",
        "# initial ensemble perturbation\n",
        "for i in range(kk):\n",
        "  enkf_po.ensemble[i].x += np.random.randn(n) * 10.0 # approximate error of the initial state\n",
        "# set observation error covariance matrix (diagonal)\n",
        "r = np.identity(n, dtype=np.float64) * obs_err_std\n",
        "# set observation operator matrix (use identity)\n",
        "h = np.identity(n, dtype=np.float64)\n",
        "x_po10loc = []\n",
        "analysis_intv = 10\n",
        "\n",
        "# MAIN LOOP\n",
        "for i in range(exp_length // analysis_intv):\n",
        "  for j in range(analysis_intv):\n",
        "    # time (i * analysis_intv + j) to (i * analysis_intv + j + 1)\n",
        "    xf = enkf_po.forward()\n",
        "  if (i + 1) * analysis_intv < exp_length:\n",
        "    if i % 100 == 0:\n",
        "      print(\"analysis \", i)\n",
        "    else:\n",
        "      print(\".\", end=\"\")\n",
        "    # multiplicative covariance inflation\n",
        "    x_mean = enkf_po.mean()\n",
        "    for ii in range(kk):\n",
        "      enkf_po.ensemble[ii].x = x_mean + (enkf_po.ensemble[ii].x - x_mean) * math.sqrt(1.1)\n",
        "    #\n",
        "    xa = enkf_po.analysis(h, obs[(i + 1) * analysis_intv, :], r)\n",
        "    x_po10loc.append(((i + 1) * analysis_intv, xa))\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRAU7oEwi9TA"
      },
      "source": [
        "rmse = []\n",
        "for xx in x_po10loc:\n",
        "  if xx[0] < nature.shape[0]:\n",
        "    rmse.append((xx[0], math.sqrt(((nature[xx[0]] - xx[1]) ** 2).sum() / n)))\n",
        "rmse = np.array(rmse) \n",
        "\n",
        "plt.plot(rmse[:, 0], rmse[:, 1])\n",
        "plt.xlabel('time step')\n",
        "plt.ylabel('root mean square error')\n",
        "print(np.mean(rmse[int(1000 / analysis_intv):, 1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x-SWFdddkFM"
      },
      "source": [
        "安定して動作するようになりました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTKzFRJPpyJZ"
      },
      "source": [
        "最後に、平方根フィルタの代表例である局所アンサンブル変換カルマンフィルタ (Local Ensemble Transform Kalman Filter, LETKF)を実装します。\n",
        "\n",
        "平方根フィルタでは、解析誤差共分散の平方根を取ることで次のステップのアンサンブル予報の初期値を得ます。この平方根の選び方は任意性があります。\n",
        "\n",
        "$$\\mathbf{dx}^{a(k)}_i = \\mathbf{x}^{a(k)}_i - \\mathbf{x}^a_i$$\n",
        "\n",
        "$$\\mathsf{Z}^a = \\frac{1}{\\sqrt{m - 1}} \\left(\n",
        "  \\mathbf{dx}^{a(1)}_i,\n",
        "  \\mathbf{dx}^{a(2)}_i, ...,\n",
        "  \\mathbf{dx}^{a(m)}_i\\right)$$\n",
        "\n",
        "$$\\mathsf{Z}^a = \\left(\\mathsf{P}^a_i \\right)^{\\frac{1}{2}}$$\n",
        "\n",
        "ここでは、解析アンサンブル摂動が予報アンサンブル摂動の線形結合で記述できると置いて、その線形変換行列 $\\mathsf{T}$ を得ます（アンサンブル変換）。\n",
        "背景共分散膨張係数を$\\rho$とすると、\n",
        "\n",
        "$$\\mathsf{Z}^a = \\mathsf{Z}^f \\mathsf{T} = \\rho^{\\frac{1}{2}}\\mathsf{Z}^f \\mathsf{T}^\\prime$$\n",
        "\n",
        "$$\\mathsf{Y}_i \\equiv \\mathsf{H}_i \\mathsf{Z}^f$$\n",
        "$\\mathsf{Y}_i$: 予報アンサンブル摂動に観測演算子をかけたもの\n",
        "\n",
        "カルマンフィルタの誤差分散の解析式に代入すると、\n",
        "\n",
        "$$\\mathsf{P}^a_i = \\left(\\mathsf{I} - \\mathsf{K}_i \\mathsf{H}_i \\right) \\mathsf{P}^f_i$$\n",
        "\n",
        "\\begin{eqnarray}\n",
        "\\mathsf{P}^a_i &=& \\mathsf{Z}^f \\mathsf{T} \\mathsf{T}^T \\left(\\mathsf{Z}^f \\right)^T \\\\\n",
        "&=& \\rho^{\\frac{1}{2}}\\mathsf{Z}^f \\mathsf{T}^\\prime {\\mathsf{T}^\\prime}^T \\left(\\rho^{\\frac{1}{2}}\\mathsf{Z}^f \\right)^T \\\\\n",
        "&=& (\\mathsf{I} - \\mathsf{K}_i \\mathsf{H}_i) \\rho^{\\frac{1}{2}}\\mathsf{Z}^f (\\rho^{\\frac{1}{2}}\\mathsf{Z}^f)^T \\\\\n",
        "&=& (\\mathsf{I} - \\rho^{\\frac{1}{2}}\\mathsf{Z}^f (\\mathsf{H}_i \\rho^{\\frac{1}{2}}\\mathsf{Z}^f)^T (\\mathsf{H}_i \\rho^{\\frac{1}{2}}\\mathsf{Z}^f (\\mathsf{H}_i \\rho^{\\frac{1}{2}}\\mathsf{Z}^f)^T + \\mathsf{R}_i)^{-1}\\mathsf{H}_i) \\rho^{\\frac{1}{2}}\\mathsf{Z}^f (\\rho^{\\frac{1}{2}}\\mathsf{Z}^f)^T \\\\\n",
        "&=& (\\mathsf{I} - \\rho \\mathsf{Z}^f \\mathsf{Y}_i^T (\\rho \\mathsf{Y}_i \\mathsf{Y}_i^T + \\mathsf{R}_i)^{-1}\\mathsf{H}_i) \\rho \\mathsf{Z}^f (\\mathsf{Z}^f)^T \\\\\n",
        "&=& \\mathsf{Z}^f (\\mathsf{I} - \\rho \\mathsf{Y}_i^T (\\rho \\mathsf{Y}_i \\mathsf{Y}_i^T + \\mathsf{R}_i)^{-1} \\mathsf{Y}_i) \\rho (\\mathsf{Z}^f)^T \\\\\n",
        "&=& \\mathsf{Z}^f (\\mathsf{I} - \\rho \\mathsf{Y}_i^T (\\rho \\mathsf{Y}_i^T + \\mathsf{Y}_i^{-1} \\mathsf{R}_i)^{-1}) \\rho (\\mathsf{Z}^f)^T \\\\\n",
        "&=& \\mathsf{Z}^f (\\mathsf{I} - \\rho (\\rho \\mathsf{I} + \\mathsf{Y}_i^{-1} \\mathsf{R}_i (\\mathsf{Y}_i^T)^{-1})^{-1}) \\rho (\\mathsf{Z}^f)^T \\\\\n",
        "&=& \\mathsf{Z}^f (\\mathsf{I} - \\rho (\\rho \\mathsf{I} + \\mathsf{Y}_i^{-1} (\\mathsf{Y}_i^T \\mathsf{R}_i^{-1})^{-1})^{-1}) \\rho (\\mathsf{Z}^f)^T \\\\\n",
        "&=& \\mathsf{Z}^f (\\mathsf{I} - \\rho (\\rho \\mathsf{I} + (\\mathsf{Y}_i^T \\mathsf{R}_i^{-1} \\mathsf{Y}_i)^{-1})^{-1}) \\rho (\\mathsf{Z}^f)^T \\\\\n",
        "&=& \\mathsf{Z}^f (\\mathsf{Y}_i^T \\mathsf{R}_i^{-1} \\mathsf{Y}_i)^{-1} (\\rho \\mathsf{I} + (\\mathsf{Y}_i^T \\mathsf{R}_i^{-1} \\mathsf{Y}_i)^{-1})^{-1} \\rho (\\mathsf{Z}^f)^T \\\\\n",
        "&=& \\mathsf{Z}^f (\\rho \\mathsf{Y}_i^T \\mathsf{R}_i^{-1} \\mathsf{Y}_i + \\mathsf{I})^{-1} \\rho (\\mathsf{Z}^f)^T \\\\\n",
        "&=& \\mathsf{Z}^f (\\mathsf{Y}_i^T \\mathsf{R}_i^{-1} \\mathsf{Y}_i + \\mathsf{I} / \\rho)^{-1} (\\mathsf{Z}^f)^T\n",
        "\\end{eqnarray}\n",
        "\n",
        "整理すると\n",
        "\n",
        "$$\\mathsf{T} \\mathsf{T}^T = (\\mathsf{Y}_i^T \\mathsf{R}_i^{-1} \\mathsf{Y}_i + \\mathsf{I} / \\rho)^{-1}$$\n",
        "\n",
        "この逆行列を解くために、右辺の固有値固有ベクトルを求めます。\n",
        "固有値を対角成分に持つ対角行列を $\\mathsf{D}$、固有ベクトルを並べた行列を $\\mathsf{U}$ とします。\n",
        "\n",
        "$$\\mathsf{U} \\mathsf{D} \\mathsf{U}^T = \\mathsf{Y}_i^T \\mathsf{R}_i^{-1} \\mathsf{Y}_i + \\mathsf{I} / \\rho$$\n",
        "\n",
        "$$\\mathsf{T} \\mathsf{T}^T = \\mathsf{U} \\mathsf{D}^{-1} \\mathsf{U}^T$$\n",
        "\n",
        "$$\\mathsf{T} = \\mathsf{U} \\mathsf{D}^{-\\frac{1}{2}}$$\n",
        "\n",
        "これを用いて、\n",
        "\n",
        "$$\\mathsf{K}_i\n",
        "= \\mathsf{P}^a_i \\mathsf{H}^T_i \\mathsf{R}^{-1}_i\n",
        "= \\mathsf{Z}^f \\mathsf{U} \\mathsf{D}^{-1} \\mathsf{U}^T \\mathsf{Y}_i^T \\mathsf{R}^{-1}_i$$\n",
        "\n",
        "実際の実装では、アンサンブル平均の更新と、アンサンブルメンバーの更新を一度に行うことが出来ます。変換の重み $\\mathsf{W}$ を\n",
        "\n",
        "$$\\mathsf{W} = \\mathsf{U} \\mathsf{D}^{-1} \\mathsf{U}^T \\mathsf{Y}_i^T \\mathsf{R}^{-1}_i (\\mathbf{y}^o_i - \\mathsf{H}_i \\mathbf{x}^f_i) + \\sqrt{m - 1} \\mathsf{U} \\mathsf{D}^{-\\frac{1}{2}}$$\n",
        "\n",
        "として、予報アンサンブル平均の列ベクトルをメンバー数分だけ並べた行列 $\\mathsf{X}^f_i$ を用いて\n",
        "\n",
        "$$\\mathsf{X}^a_i = \\mathsf{X}^f_i + \\mathsf{Z}^f \\mathsf{W}$$\n",
        "\n",
        "で各アンサンブルメンバーの解析値を列ベクトルとして並べた行列を求められます。\n",
        "\n",
        "LETKFではカルマンゲインを直接計算しないため、観測誤差を調整して近似的に共分散局所化を行います。ここでは階段関数で局所化しています。すなわち、ある点から一定の距離以内にある観測だけを用いてデータ同化を行います。この操作を各点毎に（次式では $j$ で表す）独立に行います。\n",
        "\n",
        "$$\\mathsf{X}^a_{i,j}\n",
        "= \\mathsf{X}^f_{i,j} + \\mathsf{Z}^f_j \\mathsf{W}_j$$\n",
        "\n",
        "各点で解くので、\n",
        "$\\mathsf{X}^a_{i,j}$,\n",
        "$\\mathsf{X}^f_{i,j}$,\n",
        "$\\mathsf{Z}^f_j$\n",
        "は行列ではなく行ベクトルにになります。この式ではモデルのサイズに関わる変数は無く、観測数とアンサンブル数で行列サイズが決まります。一般に観測数、アンサンブル数はモデルの自由度より十分に小さく、容易に解けるようになります。\n",
        "\n",
        "モデル格子点の数と同じ回数、LETKFの式を解く必要がありますが、各格子点の解析は互いに独立なため、並列計算に向いています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5DZ3eVOid0D"
      },
      "source": [
        "class LETKF:\n",
        "  def __init__(self, model, n = 40, f = 8, dt = 0.005, k = 20, localization = 5, inflation = 1.0):\n",
        "    \"\"\"\n",
        "    model: model constructor\n",
        "    n: model size\n",
        "    f: external forcing\n",
        "    dt: time interval of model time integration\n",
        "    n, f, dt will be passed to the model constructor\n",
        "    k: ensemble size\n",
        "    localization: localization patch radius\n",
        "    inflation: multiplicative covariance inflation\n",
        "    \"\"\"\n",
        "    self.n = n\n",
        "    self.f = f\n",
        "    self.dt = dt\n",
        "    self.k = k\n",
        "    self.localization = localization\n",
        "    self.infl = math.sqrt(inflation)\n",
        "    # models\n",
        "    self.ensemble = []\n",
        "    for i in range(k):\n",
        "      self.ensemble.append(model(n, f, dt))\n",
        "    return\n",
        "  \n",
        "  def forward(self):\n",
        "    \"\"\"\n",
        "    This function updates the model state.\n",
        "    \"\"\"\n",
        "    for i in range(self.k):\n",
        "      self.ensemble[i].runge_kutta()\n",
        "    return\n",
        "\n",
        "  def mean(self):\n",
        "    x_mean = self.ensemble[0].x.copy()\n",
        "    for i in range(1, self.k):\n",
        "      x_mean += self.ensemble[i].x\n",
        "    x_mean /= self.k\n",
        "    return x_mean\n",
        "\n",
        "  def analysis(self, h, y, r):\n",
        "    \"\"\"\n",
        "    This function performs LETKF.\n",
        "    h: observation operator matrix\n",
        "    y: a vector of observations\n",
        "    r: observation error covariance matrix\n",
        "    \"\"\"\n",
        "\n",
        "    # forecast ensemble mean\n",
        "    x = self.mean()[:, np.newaxis]\n",
        "    # forecast ensemble perturbation divided by sqrt(self.k - 1)\n",
        "    z = np.zeros((self.n, self.k), dtype=np.float64)\n",
        "    for i in range(self.k):\n",
        "      z[:, i] = self.ensemble[i].x\n",
        "    z -= x\n",
        "    z /= math.sqrt(self.k - 1)\n",
        "    # forecast ensemble perturbation in the observation space\n",
        "    hzz = h @ z\n",
        "\n",
        "    hx0 = h @ x\n",
        "    hx = np.zeros((y.shape[0], self.k), dtype=np.float64)\n",
        "    for i in range(self.k):\n",
        "      hx[:, i] = hx0[:, 0]\n",
        "    # mismatch between the forecast ensemble mean and observation (called \"innovation\")\n",
        "    y_hx = y[:, np.newaxis] - hx\n",
        "\n",
        "    # analysis at each location\n",
        "    for ia in range(self.n):\n",
        "      x_ia = x[ia, :] # ensemble mean at this location\n",
        "      z_ia = z[ia, :] # ensemble perturbation at this location\n",
        "\n",
        "      # search local observations within the localization radius\n",
        "      obs_loc = self.search_obs(ia, h)\n",
        "      n_obs_loc = len(obs_loc)\n",
        "      if n_obs_loc == 0:\n",
        "        continue\n",
        "      hz_loc = hzz[obs_loc] # forecast ensemble perturbation in the observation space at this location\n",
        "      y_hx_loc = y_hx[obs_loc, :] # innovation for local observations\n",
        "      # inverse of observation error covariance for local observations\n",
        "      if r.ndim == 1: # r is a 1-D array (only the diagonal elements are provided)\n",
        "        r_inv_loc = np.zeros((n_obs_loc, n_obs_loc), dtype=np.float64)\n",
        "        for i in range(n_obs_loc):\n",
        "          r_inv_loc[i, i] = 1.0 / r[obs_loc[i]]\n",
        "      else:\n",
        "        r_inv_loc = LA.inv(r[obs_loc, :][:, obs_loc])\n",
        "\n",
        "      # only the value at this location is updated\n",
        "      x_a = self.letkf_core(x_ia, z_ia, hz_loc, y_hx_loc, r_inv_loc)\n",
        "      for i in range(self.k):\n",
        "        self.ensemble[i].x[ia] = x_a[i]\n",
        "    return self.mean()\n",
        "\n",
        "  def search_obs(self, ia, h):\n",
        "    patch = []\n",
        "    for i in range(ia - self.localization, ia + self.localization + 1):\n",
        "      patch.append(i % self.n)\n",
        "    obs_loc = []\n",
        "    for i in range(h.shape[0]):\n",
        "      if np.max(np.abs(h[i, patch])) > 0:\n",
        "        obs_loc.append(i)\n",
        "    return obs_loc\n",
        "\n",
        "  def letkf_core(self, x, z, hz, y_hx, r_inv):\n",
        "    \"\"\"\n",
        "    x: forecast ensemble mean\n",
        "    z: forecast ensemble perturbation divided by sqrt(self.k - 1)\n",
        "    hz: z in the observation space\n",
        "    y_hz: innovation\n",
        "    r_inv: inverse of observation error covariance\n",
        "    \"\"\"\n",
        "    # ensemble transform\n",
        "    hzT_r_inv = hz.T @ r_inv\n",
        "    u_d_u = hzT_r_inv @ hz\n",
        "    for i in range(u_d_u.shape[0]):\n",
        "      u_d_u[i, i] += 1.0 / self.infl # covariance inflation is included here\n",
        "    d, u = LA.eig(u_d_u)\n",
        "    d_inv = np.identity(d.shape[0], dtype=np.float64)\n",
        "    d_inv_sqrt = np.identity(d.shape[0], dtype=np.float64)\n",
        "    for i in range(d.shape[0]):\n",
        "      d_inv[i, i] = 1.0 / d[i]\n",
        "      d_inv_sqrt[i, i] = 1.0 / math.sqrt(d[i])\n",
        "\n",
        "    w = u @ d_inv @ u.T @ hzT_r_inv @ y_hx  # mean update\n",
        "    w += (u @ d_inv_sqrt @ u.T) * math.sqrt(self.k - 1) # ensemble update\n",
        "    x_a = z @ w + x\n",
        "    return x_a\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxXyEm1Z7PaM"
      },
      "source": [
        "kk = 10 # ensemble size\n",
        "scale = 5 # localization scale\n",
        "letkf = LETKF(Lorenz96, n, k = kk, localization = scale, inflation = 1.1)\n",
        "# initial ensemble perturbation\n",
        "for i in range(kk):\n",
        "  letkf.ensemble[i].x += np.random.randn(n) * 10.0 # approximate error of the initial state\n",
        "# set observation error covariance matrix (diagonal elements only)\n",
        "r = np.ones(n, dtype=np.float64) * obs_err_std\n",
        "# set observation operator matrix (use identity)\n",
        "h = np.identity(n, dtype=np.float64)\n",
        "x_letkf10 = []\n",
        "analysis_intv = 10\n",
        "\n",
        "# MAIN LOOP\n",
        "for i in range(exp_length // analysis_intv):\n",
        "  for j in range(analysis_intv):\n",
        "    # time (i * analysis_intv + j) to (i * analysis_intv + j + 1)\n",
        "    xf = letkf.forward()\n",
        "  if (i + 1) * analysis_intv < exp_length:\n",
        "    if i % 100 == 0:\n",
        "      print(\"analysis \", i)\n",
        "    else:\n",
        "      print(\".\", end=\"\")\n",
        "    xa = letkf.analysis(h, obs[(i + 1) * analysis_intv, :], r)\n",
        "    x_letkf10.append(((i + 1) * analysis_intv, xa))\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac5ScYTq8gJS"
      },
      "source": [
        "rmse = []\n",
        "for xx in x_letkf10:\n",
        "  if xx[0] < nature.shape[0]:\n",
        "    rmse.append((xx[0], math.sqrt(((nature[xx[0]] - xx[1]) ** 2).sum() / n)))\n",
        "rmse = np.array(rmse) \n",
        "\n",
        "plt.plot(rmse[:, 0], rmse[:, 1])\n",
        "plt.xlabel('time step')\n",
        "plt.ylabel('root mean square error')\n",
        "print(np.mean(rmse[int(1000 / analysis_intv):, 1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGT9wXPOsuPi"
      },
      "source": [
        "用意してある実験はここまでです。\n",
        "\n",
        "時間があれば、パラメータを変えて色々実験してみて下さい。"
      ]
    }
  ]
}